<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Caesar Cipher</title>
    <link rel="stylesheet" href="homework2.css">
    <script src="homework2.js"></script>
    <link href="https://cdn.jsdelivr.net/npm/prismjs/themes/prism.css" rel="stylesheet" />
    <script src="https://cdn.jsdelivr.net/npm/prismjs/prism.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs/components/prism-sql.min.js"></script>
</head>
<body>
<section>
    <h2>DATASET</h2>

    <p>
        A <strong>dataset</strong> is a collection of data, organized in tables, arrays, or specific formats such as CSV or JSON.
        Nowadays, data sources are extremely varied, from customer interactions to social media platforms, also including financial transactions:
        they directly determine both the quality and utility of datasets.
    </p>
    <p>
        This information is essential for companies’ business purposes, so organizing them in an optimal way is needed.
        In this context, datasets are used to make information accessible for analysis and application.
        In this way, companies can perform specific business actions by easily cross-checking data to get better results.
    </p>

    <h3>Examples</h3>
    <ul>
        <li>Customer service datasets tracking support interactions and resolutions;</li>
        <li>Manufacturing datasets monitoring equipment performance metrics;</li>
        <li>Sales datasets analyzing transaction patterns and consumer behavior;</li>
        <li>Marketing datasets measuring campaign effectiveness and engagement.</li>
    </ul>

    <h3>Dataset’s Features</h3>
    <p>A dataset typically includes three main characteristics:</p>
    <ul>
        <li><strong>Variables:</strong> specific attributes or characteristics being studied within the dataset, often used as inputs for machine learning algorithms and statistical analysis;</li>
        <li><strong>Schemas:</strong> the dataset’s structure, including relationships and syntax between its variables;</li>
        <li><strong>Metadata:</strong> provides essential context about the dataset, including details about its origin, purpose, and usage guidelines.</li>
    </ul>

    <p>
        Different types of datasets are employed:
        <strong>unstructured</strong> ones, including text files, images, and audio, and
        <strong>structured</strong> ones, organized in tables with rows and columns.
    </p>

    <h3>Structured Dataset</h3>
    <p>
        It organizes information in predefined formats — the most common being the table, with clear rows and columns.
        Used in many critical business processes, they follow consistent schemas, enable fast querying, and support reliable analysis.
    </p>
    <p>Common examples include:</p>
    <ul>
        <li>Financial records organized in spreadsheets with defined fields for dates, amounts, and categories;</li>
        <li>Customer databases for contact information and purchase history;</li>
        <li>Inventory systems tracking product quantities, locations, and movement;</li>
        <li>Sensor data streams providing uniform metrics for equipment monitoring and predictive maintenance.</li>
    </ul>

    <h3>Unstructured Dataset</h3>
    <p>
        It contains information that doesn’t conform to traditional data models or rigid schemas.
        While it needs different processing tools, it often contains rich insights that structured data formats cannot capture.
        It is commonly used to power artificial intelligence and machine learning models.
    </p>
    <p>Common examples include:</p>
    <ul>
        <li>Text documents such as emails, reports, and web pages;</li>
        <li>Images and videos used to train machine learning models;</li>
        <li>Audio recordings from real-world applications;</li>
        <li>Chat logs and customer service transcripts.</li>
    </ul>

    <h3>Semistructured Dataset</h3>
    <p>
        While it doesn’t follow rigid schemas, it incorporates defined syntax or markers to help organize data in flexible yet parseable formats.
        This approach makes it suitable for modern data integration projects and applications that handle different data types while maintaining some structure.
    </p>
    <p>Common examples include:</p>
    <ul>
        <li>JSON, HTML, and XML files used in web applications and APIs;</li>
        <li>Log files containing both formatted fields and free-form text;</li>
        <li>Public datasets combining multiple data formats for broader accessibility.</li>
    </ul>

    <h3>Dataset Use Cases</h3>
    <p>Datasets are essential to several key business and technological initiatives. Common applications include:</p>
    <ul>
        <li>Artificial intelligence and machine learning;</li>
        <li>Data analysis and insights;</li>
        <li>Business intelligence.</li>
    </ul>

    <h3>Final Considerations</h3>
    <ul>
        <li><strong>Data Quality:</strong> Maintaining data integrity and quality is critical. Incomplete or inaccurate data can lead to misleading results. Validation techniques help ensure accuracy and consistency.</li>
        <li><strong>Interoperability and Data Integration:</strong> Integrating datasets from different sources or formats can be challenging. Creating unified schemas or standardizing data formats improves compatibility.</li>
        <li><strong>Ethics and Bias:</strong> Datasets containing personal or biased data raise ethical and privacy concerns. Evaluating and cleaning training data helps mitigate such issues.</li>
        <li><strong>Dataset Management:</strong> As data volumes grow, robust processes for dataset creation, maintenance, and governance are necessary to ensure quality and compliance with privacy regulations.</li>
    </ul>

    <p><em>Source: <a href="https://www.ibm.com/think/topics/dataset" target="_blank">IBM Think — Dataset Topic</a></em></p>
</section>

<hr>

<section>
    <h2>DISTRIBUTION</h2>

    <p>
        A <strong>statistical data distribution</strong> is a function that shows the possible values of a variable and how frequently they occur.
        It provides a mathematical description of the data’s behavior, indicating where most data points are concentrated and how they are spread out.
    </p>

    <p>
        The simplest example is a six-sided die, numbered from 1 to 6.
        The probability of getting any number at random is exactly the same — one-sixth — and the probability of getting a different number is zero.
    </p>

    <p>
        The distribution of an event consists not only of observed input values but of all possible ones.
        Each probability distribution is associated with a graph describing the likelihood of occurrence of every event.
    </p>

    <h3>Types of Distribution Functions</h3>
    <ul>
        <li><strong>Probability Function (PF):</strong> assigns probabilities to different possible outcomes in a dataset.</li>
        <li><strong>Probability Density Function (PDF):</strong> used for continuous variables, showing the likelihood of values falling within a certain range.</li>
        <li><strong>Cumulative Distribution Function (CDF):</strong> represents the probability that a variable takes a value less than or equal to a specific point.</li>
    </ul>

    <h3>Categories of Statistical Distribution</h3>
    <ul>
        <li><strong>Discrete Distribution:</strong> used when the data can take only specific separate values, like integers.</li>
        <li><strong>Continuous Distribution:</strong> used when the data can take any value within a range, including fractions and decimals.</li>
    </ul>

    <h3> Properties of a Distribution</h3>
    <ul>
        <li><strong>Mean:</strong> the average value of all data points; indicates the central tendency of the dataset.</li>
        <li><strong>Variance and Standard Deviation:</strong> measure how spread out the data points are around the mean. Variance calculates the average of the squared differences from the mean, while the standard deviation is its square root.</li>
        <li><strong>Skewness:</strong> measures the degree of symmetry or asymmetry of the distribution.</li>
        <li><strong>Mode:</strong> the value that appears most frequently, representing the peak of the distribution.</li>
    </ul>

    <p>
        <em>Sources:</em><br>
        <a href="https://www.geeksforgeeks.org/engineering-mathematics/introduction-of-statistical-data-distributions/" target="_blank">
            GeeksforGeeks — Introduction of Statistical Data Distributions
        </a><br>
        <a href="https://365datascience.com/tutorials/statistics-tutorials/distribution-in-statistics/" target="_blank">
            365DataScience — Distribution in Statistics
        </a>
    </p>
</section>

<h3>Example of a Dataset: Cybercrimes</h3>

<pre><code class="language-sql">
CREATE TABLE CyberIncidenti (
  id INT PRIMARY KEY,
  gravita INT,
  categoria TEXT
);

INSERT INTO CyberIncidenti (id, gravita, categoria) VALUES
(1, 2, 'phishing'),
(2, 3, 'malware'),
(3, 1, 'brute-force'),
(4, 2, 'phishing'),
(5, 4, 'ransomware'),
(6, 3, 'malware'),
(7, 1, 'brute-force'),
(8, 3, 'malware'),
(9, 5, 'ransomware'),
(10, 2, 'phishing'),
(11, 2, 'brute-force'),
(12, 4, 'malware'),
(13, 1, 'phishing'),
(14, 2, 'phishing'),
(15, 5, 'ransomware'),
(16, 1, 'brute-force'),
(17, 3, 'malware'),
(18, 1, 'phishing'),
(19, 4, 'malware'),
(20, 5, 'ransomware');
</code></pre>

<h3>Queries to calculate the univariate distributions and their results</h3>
<pre><code class="language-sql">
    SELECT gravita, COUNT(*) AS tot, ROUND(100.0 * COUNT(*) / (SELECT COUNT(*) FROM CyberIncidenti), 2) AS pct
    FROM CyberIncidenti
    GROUP BY gravita
    ORDER BY gravita;
</code></pre>

<img src="images/query_gravita.jpg" alt="">

<pre><code>
    SELECT categoria, COUNT(*) AS tot, ROUND(100.0 * COUNT(*) / (SELECT COUNT(*) FROM CyberIncidenti), 2) AS pct
    FROM CyberIncidenti
    GROUP BY categoria
    ORDER BY categoria;

</code></pre>

<img src="images/query_categoria.jpg" alt="">

<h3> Query to calculate the bivariate distribution</h3>
<pre><code class="language-sql">
    SELECT categoria, gravita, COUNT(*) AS frequenza, ROUND(100.0 * COUNT(*) / (SELECT COUNT(*) FROM CyberIncidenti), 2) AS percentuale_totale
    FROM CyberIncidenti
    GROUP BY categoria, gravita
    ORDER BY categoria, gravita;

</code></pre>

<img src="images/query_distribuzione_bivariata.jpg" alt="">

<h2>Caesar Cipher and Letter Distribution</h2>

<section>
    <h3> Original Text</h3>
    <textarea id="originalText" rows="10" cols="50" placeholder="Enter your text here..."></textarea>
    <label for="shift">Shift:</label>
    <input type="number" id="shift" min="1" max="25">
    <button onclick="encryptText()">Encrypt</button>
</section>

<section>
    <h3> Encrypted Text</h3>
    <textarea id="encryptedText" rows="10" cols="50" placeholder="Encrypted result will appear here..."></textarea>
</section>

<section>
    <h3> Letter Frequency Analysis</h3>
    <div style="flex: 1; min-width: 300px;">
        <h4>Original Text Frequency</h4>
        <pre id="freqOriginal"></pre>
    </div>
    <div style="flex: 1; min-width: 300px;">
        <h4>Encrypted Text Frequency</h4>
        <pre id="freqEncrypted"></pre>
    </div>
</section>



</body>
</html>